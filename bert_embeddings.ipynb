{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshit-g/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model to be Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"  \n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Looping Mechanism**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           documents  num_documents  \\\n",
      "0  ['A Ware Police patrol car passes the yellow h...              4   \n",
      "1  ['Significance \\n \\n A large body of medical r...              5   \n",
      "2  ['A Syrian warplane has destroyed a petrol sta...              4   \n",
      "3  ['A political cartoon, published in a newspape...              7   \n",
      "4  ['Megyn Kelly takes issue with \\'NYT\\' book re...              4   \n",
      "\n",
      "                                             summary  \n",
      "0  – A defrocked priest at the heart of Boston's ...  \n",
      "1  – Women suffering from a heart attack seem to ...  \n",
      "2  – A new UN analysis finds that at least 60,000...  \n",
      "3  – The first government shutdown since the Clin...  \n",
      "4  – Megyn Kelly's memoir is out next week, and s...  \n"
     ]
    }
   ],
   "source": [
    "#load csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#load csv\n",
    "df = pd.read_csv('multi_news/sample_train.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Example text 1\",\n",
    "    \"Another example text with a longer sequence.\",\n",
    "    \"Short text\",\n",
    "]\n",
    "\n",
    "# Move the model to the specified device\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the maximum token length you want to limit to\n",
    "max_token_length = 20  # You can adjust this based on your requirements\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "encoded_texts = {}\n",
    "\n",
    "# Loop through each text and encode it\n",
    "for text in texts:\n",
    "    # Tokenize the text and ensure it doesn't exceed max_token_length\n",
    "    tokenized_text = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_token_length, return_tensors=\"pt\")\n",
    "    \n",
    "    # Move the tokenized input to the same device as the model\n",
    "    tokenized_text = tokenized_text.to(device)\n",
    "\n",
    "    # Pass the tokenized input through the BERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_text)\n",
    "\n",
    "    # Extract the embeddings from the model output\n",
    "    embeddings = outputs.last_hidden_state  # This contains the embeddings\n",
    "\n",
    "    # Store the text and its corresponding embeddings in the dictionary\n",
    "    encoded_texts[text] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Example text 1': tensor([[[-0.3035,  0.0985, -0.1054,  ..., -0.3088,  0.1413,  0.6364],\n",
      "         [-0.3649,  0.3467, -0.8662,  ..., -0.1882,  0.8155,  0.0166],\n",
      "         [-0.0537,  0.2979,  0.3368,  ..., -0.3639,  0.1457,  0.4011],\n",
      "         ...,\n",
      "         [-0.5190, -0.5021,  0.1325,  ..., -0.0988,  0.2699,  0.1380],\n",
      "         [-0.3855, -0.3380,  0.2266,  ..., -0.1350,  0.2796,  0.0815],\n",
      "         [-0.5652, -0.4774,  0.0059,  ..., -0.0934,  0.2305,  0.0593]]],\n",
      "       device='cuda:0'), 'Another example text with a longer sequence.': tensor([[[-0.3991, -0.2916, -0.1429,  ..., -0.4051,  0.2791,  0.7713],\n",
      "         [-0.4444, -1.0624, -0.3955,  ..., -0.1943,  1.1572,  0.2617],\n",
      "         [-0.7537,  0.1376, -0.3634,  ..., -0.6728,  0.3218,  0.1036],\n",
      "         ...,\n",
      "         [-0.0665, -0.2493,  0.0926,  ..., -0.2028,  0.1874,  0.2085],\n",
      "         [-0.1050, -0.3938,  0.0872,  ..., -0.0827,  0.2565,  0.2451],\n",
      "         [-0.7000, -1.0117, -0.4994,  ...,  0.4737,  0.4898,  0.1619]]],\n",
      "       device='cuda:0'), 'Short text': tensor([[[-0.4467,  0.0273, -0.2823,  ..., -0.1005,  0.1712,  0.6276],\n",
      "         [-0.1274,  0.3038, -0.3842,  ...,  0.1436,  0.6181,  0.1373],\n",
      "         [-0.0809, -0.0930, -0.1045,  ..., -0.7356, -0.1712,  0.0290],\n",
      "         ...,\n",
      "         [-0.3110, -0.3051,  0.4353,  ..., -0.0868, -0.0741,  0.1943],\n",
      "         [-0.4011, -0.3294,  0.3693,  ...,  0.0392, -0.0666,  0.3381],\n",
      "         [-0.1551, -0.2330,  0.5518,  ..., -0.1530, -0.0608,  0.2260]]],\n",
      "       device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
