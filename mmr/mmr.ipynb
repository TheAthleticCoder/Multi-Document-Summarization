{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PorterStemmer from nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def cleanData(sentence):\n",
    "    return stemmer.stem(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculateSimilarity(sentence, doc):\n",
    "    if doc == []:\n",
    "        return 0\n",
    "\n",
    "    vocab = {}\n",
    "\n",
    "    # For each word in the sentence, add it to the vocabulary dictionary\n",
    "    for word in sentence:\n",
    "        vocab[word] = 0\n",
    "\n",
    "    # Initialize an empty string to hold the document in one sentence\n",
    "    docInOneSentence = ''\n",
    "\n",
    "    # For each term in the document, add it to the docInOneSentence string\n",
    "    # and add each word in the term to the vocabulary dictionary\n",
    "    for t in doc:\n",
    "        docInOneSentence += (t + ' ')\n",
    "        for word in t.split():\n",
    "            vocab[word]=0\n",
    "\n",
    "    # Initialize a CountVectorizer with the vocabulary dictionary as the vocabulary\n",
    "    cv = CountVectorizer(vocabulary=vocab.keys())\n",
    "\n",
    "    # Fit transform the document into a vector\n",
    "    docVector = cv.fit_transform([docInOneSentence])\n",
    "    sentenceVector = cv.fit_transform([sentence])\n",
    "\n",
    "    return cosine_similarity(docVector, sentenceVector)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(x):\n",
    "    x = ' '.join(x)\n",
    "    x = x.split('\\n')\n",
    "    \n",
    "    # Filter out any strings in the list that are just a space\n",
    "    x = list(filter(lambda s: not s == ' ', x))\n",
    "    \n",
    "    # Remove leading and trailing whitespace from each string in the list\n",
    "    x = list(map(lambda s: s.strip(), x))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(texts, sentences, clean, originalSentenceOf):\n",
    "    # Split the text into sentences\n",
    "    parts = texts.split('.')\n",
    "    \n",
    "    for part in parts:\n",
    "        cl = cleanData(part)\n",
    "        \n",
    "        sentences.append(part)\n",
    "        clean.append(cl)\n",
    "        \n",
    "        # Map the cleaned part to the original part in the originalSentenceOf dictionary\n",
    "        originalSentenceOf[cl] = part\n",
    "    \n",
    "    # Remove duplicates from the clean list by converting it to a set\n",
    "    setClean = set(clean)\n",
    "\n",
    "    return setClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Handlers.SIG_DFL: 0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import signal\n",
    "\n",
    "# Define a handler function that raises an exception when called\n",
    "def handler(signum, frame):\n",
    "    raise Exception(\"Function execution took too long\")\n",
    "\n",
    "# Set the alarm signal handler to the handler function\n",
    "# When the alarm signal is received, the handler function will be called\n",
    "signal.signal(signal.SIGALRM, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "import operator\n",
    "\n",
    "def get_mmr(doc, alpha):\n",
    "    try:\n",
    "        # Set an alarm for 60 seconds\n",
    "        signal.alarm(60)\n",
    "        \n",
    "        sentences = []\n",
    "        clean = []\n",
    "        originalSentenceOf = {}\n",
    "\n",
    "        # Get the set of cleaned sentences from the document\n",
    "        cleanSet = get_sentences(doc, sentences, clean, originalSentenceOf)\n",
    "\n",
    "        scores = {}\n",
    "        \n",
    "        # For each cleaned sentence, calculate its score and add it to the scores dictionary\n",
    "        for data in clean:\n",
    "            temp_doc = cleanSet - set([data])\n",
    "            score = calculateSimilarity(data, list(temp_doc))\n",
    "            scores[data] = score\n",
    "\n",
    "        # Calculate the number of sentences to include in the summary\n",
    "        n = 20 * len(sentences) / 100\n",
    "\n",
    "        summarySet = []\n",
    "        \n",
    "        while n > 0:\n",
    "            mmr = {}\n",
    "            \n",
    "            # For each sentence, calculate its MMR and add it to the mmr dictionary\n",
    "            for sentence in scores.keys():\n",
    "                if not sentence in summarySet:\n",
    "                    mmr[sentence] = alpha * scores[sentence] - (1-alpha) * calculateSimilarity(sentence, summarySet)\t\n",
    "            \n",
    "            if mmr == {}:\n",
    "                break\n",
    "            \n",
    "            selected = max(mmr.items(), key=operator.itemgetter(1))[0]\t\n",
    "            summarySet.append(selected)\n",
    "            \n",
    "            n -= 1\n",
    "\n",
    "        # Get the original form of the sentences in the summary set\n",
    "        original = [originalSentenceOf[sentence].strip() for sentence in summarySet]\n",
    "        \n",
    "        # Return the original sentences\n",
    "        return original\n",
    "    except Exception as e:\n",
    "        # If an exception occurs, return an empty list\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact multi_news:v0, 672.12MB. 3 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "Done. 0:0:2.5\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Create an API object to interact with the Weights & Biases service\n",
    "api = wandb.Api()\n",
    "\n",
    "artifact = api.artifact('ire-shshsh/mdes/multi_news:v0', type='dataset')\n",
    "\n",
    "path_to_file = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mn'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path_to_file = './our_dataset - Sheet1.csv'\n",
    "path_to_file = 'mn'\n",
    "path_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# for file in os.listdir(path_to_file):\n",
    "#     # if file is a csv file\n",
    "#     if file.endswith('.csv'):\n",
    "#         # get the file wihout the extension\n",
    "#         file = file.split('.')[0]\n",
    "#         print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 1624.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 1318.46it/s]\n",
      "9it [00:00, 1965.06it/s]\n",
      "9it [00:00, 2260.00it/s]\n",
      "9it [00:00, 1527.48it/s]\n",
      "9it [00:00, 2173.34it/s]\n",
      "9it [00:00, 1009.16it/s]\n",
      "9it [00:00, 1259.85it/s]\n",
      "9it [00:00, 1493.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# for all files in path_to_file\n",
    "for file in os.listdir(path_to_file):\n",
    "    # if file is a csv file\n",
    "    if file.endswith('.csv'):\n",
    "        # read the csv file\n",
    "        df = pd.read_csv(os.path.join(path_to_file, file))\n",
    "\n",
    "        df['documents'] = df['documents'].apply(lambda x: eval(x))\n",
    "        df['concat_doc'] = df['documents'].apply(lambda x: concat(x))\n",
    "\n",
    "        # Loop over different alpha values\n",
    "        for alpha in [0.2, 0.5, 0.8]:\n",
    "            # Initialize an empty 'mmr' column\n",
    "            df['mmr'] = ''\n",
    "\n",
    "            file_name = file.split('.')[0]\n",
    "\n",
    "            # Write the header to the file and remove the dropped columns\n",
    "            df.drop(columns=['concat_doc']).iloc[0:0].to_csv(f'{file_name}_{alpha}.csv', index=False)\n",
    "\n",
    "            for i, row in tqdm(df.iterrows()):\n",
    "                df.at[i, 'mmr'] = get_mmr(df.at[i, 'concat_doc'], alpha)\n",
    "\n",
    "                # If the MMR is an empty list, skip this row\n",
    "                if df.at[i, 'mmr'] == []:\n",
    "                    continue\n",
    "\n",
    "                row = df.iloc[i].drop(['concat_doc'])\n",
    "\n",
    "                # Save the current row to the file\n",
    "                row.to_frame().T.to_csv(f'{file_name}_{alpha}.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Weights & Biases run\n",
    "run = wandb.init(entity='ire-shshsh', project='mmr', job_type='mmr')\n",
    "\n",
    "for alpha in [0.2, 0.5, 0.8]:\n",
    "    artifact = wandb.Artifact(name=f'multi_news_{alpha}', type='dataset')\n",
    "    for file in ['train', 'validation', 'test']:\n",
    "        artifact.add_file(f'{file}_{alpha}.csv')\n",
    "    run.log_artifact(artifact)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/shu7bh/.conda/envs/main/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/shu7bh/.conda/envs/main/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/shu7bh/.conda/envs/main/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/shu7bh/.conda/envs/main/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/shu7bh/.conda/envs/main/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/shu7bh/.conda/envs/main/lib/python3.11/asyncio/base_events.py\", line 1884, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shu7bh/.conda/envs/main/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_111128/1407592094.py\", line 5, in handler\n",
      "    raise Exception(\"Function execution took too long\")\n",
      "Exception: Function execution took too long\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import wandb\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(path_to_file)\n",
    "# df['documents'] = df['documents'].apply(lambda x: eval(x))\n",
    "# df['concat_doc'] = df['documents'].apply(lambda x: concat(x))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from icecream import ic\n",
    "\n",
    "# df = pd.read_csv(path_to_file)\n",
    "# df['concat_doc'] = df['doc1'] + ' ' + df['doc2'] + ' ' + df['doc3']\n",
    "# df.drop(['doc1', 'doc2', 'doc3'], axis=1, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "\n",
    "# # Initialize a Weights & Biases run\n",
    "# # run = wandb.init(entity='ire-shshsh', project='mmr', job_type='mmr')\n",
    "\n",
    "# # Loop over different alpha values\n",
    "# for alpha in [0.2, 0.5, 0.8]:\n",
    "#     # Load the data from the CSV file\n",
    "#     # df = pd.read_csv(path_to_file)\n",
    "\n",
    "#     # df['abstracts'] = df['abstracts'].progress_apply(lambda x: eval(x))\n",
    "\n",
    "#     # df['concat_doc'] = df['abstracts'].progress_apply(lambda x: concat(x))\n",
    "\n",
    "#     # Concatenate the documents in each row\n",
    "#     # df['concat_doc'] = df['doc1'] + df['doc2'] + df['doc3']\n",
    "\n",
    "#     # Initialize an empty 'mmr' column\n",
    "#     df['mmr'] = ''\n",
    "\n",
    "#     # Write the header to the file and remove the dropped columns\n",
    "#     df.drop(columns=['concat_docs']).iloc[0:0].to_csv(\n",
    "#         f'train_{alpha}.csv', index=False)\n",
    "\n",
    "#     for i, row in tqdm(df.iterrows()):\n",
    "#         df.at[i, 'mmr'] = get_mmr(df.at[i, 'concat_doc'], alpha)\n",
    "\n",
    "#         # If the MMR is an empty list, skip this row\n",
    "#         if df.at[i, 'mmr'] == []:\n",
    "#             continue\n",
    "\n",
    "#         row = df.iloc[i].drop(['concat_doc'])\n",
    "\n",
    "#         # Save the current row to the file\n",
    "#         row.to_frame().T.to_csv(\n",
    "#             f'test_{alpha}.csv', mode='a', header=False, index=False)\n",
    "\n",
    "#     # Drop the 'concat_doc' and 'name' columns from the DataFrame\n",
    "#     # df.drop(['concat_doc', 'name'], axis=1, inplace=True)\n",
    "\n",
    "#     # Save the DataFrame to a CSV file\n",
    "#     # df.to_csv(f'test_{alpha}.csv', index=False)\n",
    "\n",
    "#     artifact = wandb.Artifact(name=f'multi_news_{alpha}', type='dataset')\n",
    "#     artifact.add_file(f'train_{alpha}.csv')\n",
    "\n",
    "#     # run.log_artifact(artifact)\n",
    "\n",
    "# # wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to print the time taken by the process\n",
    "# print str(time.time() - start)\n",
    "\n",
    "# Uncomment to print the summary\n",
    "# print ('\\nSummary:\\n')\n",
    "# for sentence in summarySet:\n",
    "# \tprint (originalSentenceOf [sentence].lstrip(' '))\n",
    "# print()\n",
    "\n",
    "# Print a separator\n",
    "# print '============================================================='\n",
    "# print '\\nOriginal Passages:\\n'\n",
    "\n",
    "# Import the termcolor module for colored output\n",
    "# from termcolor import colored\n",
    "\n",
    "# For each sentence in the cleaned data\n",
    "# for sentence in clean:\n",
    "# \t# If the sentence is in the summary set, print it in red\n",
    "# \tif sentence in summarySet:\n",
    "# \t\tprint colored(originalSentenceOf[sentence].lstrip(' '), 'red')\n",
    "# \t# Otherwise, print it in the default color\n",
    "# \telse:\n",
    "# \t\tprint originalSentenceOf[sentence].lstrip(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
